words[1]
words[1:round(length(words)/3)]
json_s1 <- toJSON(words[1:round(length(words)/3)], pretty = TRUE)
jason_s1
json_s1
json_s1 <- toJSON(words[round(length(words)/3)]:end(), pretty = TRUE)
240*3
json_s2 <- toJSON(words[round(length(words)/3)+1:2*round(length(words)/3)], pretty = TRUE)
jason_s2
json_s2
2*round(length(words)/3)
words[round(length(words)/3)+1:2*round(length(words)/3)]
words[round(length(words)/3)+1]
View(wordlist)
words[round(length(words)/3)+1:ound(length(words)/3)+2]
words[round(length(words)/3)+1:round(length(words)/3)+2]
length(words)
idx1 <- round(length(words))
idx1 <- round(length(words)/num_sessions)
num_sessions <- 3
idx1 <- round(length(words)/num_sessions)
idx2 <- idx1 + 1
round(2*length(words)/num_sessions)
# Determine indices for session split
num_sessions <- 3
index1 <- round(length(words)/num_sessions)
index2 <- round(2*length(words)/num_sessions)
242-1
483-242
725-483
json_s1 <- toJSON(words[1:index1], pretty = TRUE)
json_s2 <- toJSON(words[index1+1:index2], pretty = TRUE)
json_s3 <- toJSON(words[index2+1:length(words)], pretty = TRUE)
json_s1
json_s2
json_s3
words[index2+1:length(words)
]
index2+1
words[484:725]
length(words)
source('~/GitHub/sourcemem_online/experiment/stimuli/csv_to_json.R', echo=TRUE)
json_s3
s1 <- words[1:index1]
s2 <- words[index1+1:index2]
s3 <- words[index2+1:length(words)]
d1
s1
s2
s3
index1+1
index2
split_sessions <- chunk(words,3)
chunk <- function(x,n) split(x, cut(seq_along(x), n, labels = FALSE))
split_sessions <- chunk(words,3)
View(split_sessions)
split_sessions.1
split_sessions[1]
split_sessions[2]
split_sessions[3]
source('~/GitHub/sourcemem_online/experiment/stimuli/csv_to_json.R', echo=TRUE)
json_s1
View(sessions)
json_s2
json_s3
completed.users <- get.completed.users(SERVER.BASE.URL, SERVER.PORT,
SERVER.MASTER.API.KEY)
source('~/GitHub/sourcemem_online/analysis/sourcemem-online.R', echo=TRUE)
function (..., sep = " ", collapse = NULL)
source('~/GitHub/sourcemem_online/analysis/sourcemem-online.R', echo=TRUE)
## Connection parameters
SERVER.BASE.URL <- "https://jzhou-sourcemem-online.appspot.com"
source('~/GitHub/sourcemem_online/analysis/sourcemem-online.R', echo=TRUE)
SERVER.BASE.URL <- "https://jzhou-sourcemem-online.appspot.com"
SERVER.PORT <- NULL
SERVER.MASTER.API.KEY <- "zjFdXfQ64sgAVwQMx84IhzqzUPygpSguUkeLKLqQBIyxo8kP3yphBqF9ysd4IQsA" # <-- This needs to be in agreement with
# whatever is on the server.
#####
setwd("~/GitHub/sourcemem_online/analysis")
source("access-data.R")
started.users <- get.started.users(SERVER.BASE.URL, SERVER.PORT,
SERVER.MASTER.API.KEY)
View(completed.users)
View(started.users)
this.user.info <- get.user.information(SERVER.BASE.URL, completed.users[[1]],
SERVER.PORT, SERVER.MASTER.API.KEY)
get.user.information(SERVER.BASE.URL, completed.users[[1]],
SERVER.PORT, SERVER.MASTER.API.KEY)
get.user.information(SERVER.BASE.URL, completed.users[[1]],
SERVER.PORT, SERVER.MASTER.API.KEY)$external_id
get.user.information(SERVER.BASE.URL, completed.users[[2]],
SERVER.PORT, SERVER.MASTER.API.KEY)$external_id
get.user.information(SERVER.BASE.URL, started.users[[1]],
SERVER.PORT, SERVER.MASTER.API.KEY)$external_id
get.user.information(SERVER.BASE.URL, started.users[[2]],
SERVER.PORT, SERVER.MASTER.API.KEY)$external_id
get.user.information(SERVER.BASE.URL, started.users[[3]],
SERVER.PORT, SERVER.MASTER.API.KEY)$external_id
source('~/GitHub/sourcemem_online/analysis/sourcemem-online.R', echo=TRUE)
this.user.data <- get.last.experiment.data.by.user.id(SERVER.BASE.URL, started.users[[1]],
SERVER.PORT, SERVER.MASTER.API.KEY)
data <- data.frame(matrix(ncol=9,nrow=length(this.user.data$present_trials), dimnames=list(NULL, c("word", "is_sequential",
"recog_rating","recog_RT","target_angle",
"response_angle","response_error","source_RT", "valid_RT"))))
## Extract presentation data
for(i in 1:length(this.user.data$present_trials)){
data$word[i] <- this.user.data$present_trials[[i]]$target_word
data$is_sequential[i] <- this.user.data$present_trials[[i]]$presentation_sequential
}
## Function to sort through the scrambled blocks and find the index needed for extraction
find_recog_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$stimulus == x){
return(i)
}
}
}
## Function to normalise angles to be between 0 and 2*pi
## (This should only be necessary for "test03" pilot data, as angles in subsequent datasets should be normalised)
normalise_angle <- function(angle){
if (angle < 0){
angle <- angle + 2*pi
}
return(angle)
}
## The stimulus word is called "target_angle" for the recall trials. Could change how it is named in the database,
## but easier for now to just use the different name here
find_source_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$target_word == x){
return(i)
}
}
}
## Extract recognition data
words <- unique(data$word)
for (i in 1:length(words)){
index <- find_recog_index(words[i],this.user.data$confidence_trials)
data$recog_rating[i] <- this.user.data$confidence_trials[[index]]$response
data$recog_RT[i] <- this.user.data$confidence_trials[[index]]$rt
}
## Extract source recall data
for (i in 1:length(words)){
index <- find_source_index(words[i],this.user.data$recall_trials)
data$target_angle[i] <- this.user.data$recall_trials[[index]]$target_angle
data$response_angle[i] <- normalise_angle(this.user.data$recall_trials[[index]]$hitting_angle)
data$response_error[i] <- this.user.data$recall_trials[[index]]$angular_error
data$source_RT[i] <- this.user.data$recall_trials[[index]]$response_time
data$valid_RT [i] <- (this.user.data$recall_trials[[index]]$num_fast_attempts == 0 &&
this.user.data$recall_trials[[index]]$num_slow_attempts == 0)
}
## Aggregate performance as reciprocal of the SD of angular error.
prec <- 1/sd(data$response_error)
## Plot histograms of response error and response times for this participant
library(ggplot2)
error <- ggplot(data = data, aes(x = response_error)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Error (radians)", y = "Frequency") +
theme_classic()
rt <- ggplot(data = data, aes(x = source_RT)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Time (ms)", y = "Frequency") +
theme_classic()
## Save all users data
# for(i in 1:length(completed.users)){
#   this.user.data <- get.last.experiment.data.by.user.id(SERVER.BASE.URL, completed.users[[i]],
#                                                         SERVER.PORT, SERVER.MASTER.API.KEY)
#   filename = sprintf('Subject%s.RData', i)
#   save(this.user.data, file = filename)
# }
error
View(data)
rt
error
View(this.user.info)
View(this.user.data)
## Extract the required information for each stimuli across the trial types.
data <- data.frame(matrix(ncol=9,nrow=length(this.user.data$present_trials), dimnames=list(NULL, c("word", "is_sequential",
"recog_rating","recog_RT","target_angle",
"response_angle","response_error","source_RT", "valid_RT"))))
## Extract presentation data
for(i in 1:length(this.user.data$present_trials)){
data$word[i] <- this.user.data$present_trials[[i]]$target_word
data$is_sequential[i] <- this.user.data$present_trials[[i]]$presentation_sequential
}
## Function to sort through the scrambled blocks and find the index needed for extraction
find_recog_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$stimulus == x){
return(i)
}
}
}
## Function to normalise angles to be between 0 and 2*pi
## (This should only be necessary for "test03" pilot data, as angles in subsequent datasets should be normalised)
normalise_angle <- function(angle){
if (angle < 0){
angle <- angle + 2*pi
}
return(angle)
}
## The stimulus word is called "target_angle" for the recall trials. Could change how it is named in the database,
## but easier for now to just use the different name here
find_source_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$target_word == x){
return(i)
}
}
}
## Extract recognition data
words <- unique(data$word)
for (i in 1:length(words)){
index <- find_recog_index(words[i],this.user.data$confidence_trials)
data$recog_rating[i] <- this.user.data$confidence_trials[[index]]$response
data$recog_RT[i] <- this.user.data$confidence_trials[[index]]$rt
}
## Extract source recall data
for (i in 1:length(words)){
index <- find_source_index(words[i],this.user.data$recall_trials)
data$target_angle[i] <- this.user.data$recall_trials[[index]]$target_angle
data$response_angle[i] <- this.user.data$recall_trials[[index]]$hitting_angle
data$response_error[i] <- this.user.data$recall_trials[[index]]$angular_error
data$source_RT[i] <- this.user.data$recall_trials[[index]]$response_time
data$valid_RT [i] <- (this.user.data$recall_trials[[index]]$num_fast_attempts == 0 &&
this.user.data$recall_trials[[index]]$num_slow_attempts == 0)
}
## Aggregate performance as reciprocal of the SD of angular error.
prec <- 1/sd(data$response_error)
## Plot histograms of response error and response times for this participant
library(ggplot2)
error <- ggplot(data = data, aes(x = response_error)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Error (radians)", y = "Frequency") +
theme_classic()
rt <- ggplot(data = data, aes(x = source_RT)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Time (ms)", y = "Frequency") +
theme_classic()
error
View(data)
this.user.data <- get.last.experiment.data.by.user.id(SERVER.BASE.URL, started.users[[2]],
SERVER.PORT, SERVER.MASTER.API.KEY)
this.user.info <- get.user.information(SERVER.BASE.URL, started.users[[2]],
SERVER.PORT, SERVER.MASTER.API.KEY)
this.user.info$external_id
## Extract the required information for each stimuli across the trial types.
data <- data.frame(matrix(ncol=9,nrow=length(this.user.data$present_trials), dimnames=list(NULL, c("word", "is_sequential",
"recog_rating","recog_RT","target_angle",
"response_angle","response_error","source_RT", "valid_RT"))))
## Extract presentation data
for(i in 1:length(this.user.data$present_trials)){
data$word[i] <- this.user.data$present_trials[[i]]$target_word
data$is_sequential[i] <- this.user.data$present_trials[[i]]$presentation_sequential
}
## Function to sort through the scrambled blocks and find the index needed for extraction
find_recog_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$stimulus == x){
return(i)
}
}
}
## The stimulus word is called "target_angle" for the recall trials. Could change how it is named in the database,
## but easier for now to just use the different name here
find_source_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$target_word == x){
return(i)
}
}
}
## Extract recognition data
words <- unique(data$word)
for (i in 1:length(words)){
index <- find_recog_index(words[i],this.user.data$confidence_trials)
data$recog_rating[i] <- this.user.data$confidence_trials[[index]]$response
data$recog_RT[i] <- this.user.data$confidence_trials[[index]]$rt
}
## Extract source recall data
for (i in 1:length(words)){
index <- find_source_index(words[i],this.user.data$recall_trials)
data$target_angle[i] <- this.user.data$recall_trials[[index]]$target_angle
data$response_angle[i] <- this.user.data$recall_trials[[index]]$hitting_angle
data$response_error[i] <- this.user.data$recall_trials[[index]]$angular_error
data$source_RT[i] <- this.user.data$recall_trials[[index]]$response_time
data$valid_RT [i] <- (this.user.data$recall_trials[[index]]$num_fast_attempts == 0 &&
this.user.data$recall_trials[[index]]$num_slow_attempts == 0)
}
## Aggregate performance as reciprocal of the SD of angular error.
prec <- 1/sd(data$response_error)
## Plot histograms of response error and response times for this participant
library(ggplot2)
error <- ggplot(data = data, aes(x = response_error)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Error (radians)", y = "Frequency") +
theme_classic()
rt <- ggplot(data = data, aes(x = source_RT)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Time (ms)", y = "Frequency") +
theme_classic()
error
rt
error
View(data)
error <- ggplot(data = data, aes(x = response_error)) +
geom_histogram(bins = 30) +
labs(title ="All Recognition Ratings", x = "Response Error (radians)", y = "Frequency") +
theme_classic()
rt <- ggplot(data = data, aes(x = source_RT)) +
geom_histogram(bins = 30) +
labs(title ="All Recognition Ratings", x = "Response Time (ms)", y = "Frequency") +
theme_classic()
error
rt
this.user.data <- get.last.experiment.data.by.user.id(SERVER.BASE.URL, started.users[[1]],
SERVER.PORT, SERVER.MASTER.API.KEY)
data <- data.frame(matrix(ncol=9,nrow=length(this.user.data$present_trials), dimnames=list(NULL, c("word", "is_sequential",
"recog_rating","recog_RT","target_angle",
"response_angle","response_error","source_RT", "valid_RT"))))
## Extract presentation data
for(i in 1:length(this.user.data$present_trials)){
data$word[i] <- this.user.data$present_trials[[i]]$target_word
data$is_sequential[i] <- this.user.data$present_trials[[i]]$presentation_sequential
}
## Function to sort through the scrambled blocks and find the index needed for extraction
find_recog_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$stimulus == x){
return(i)
}
}
}
## The stimulus word is called "target_angle" for the recall trials. Could change how it is named in the database,
## but easier for now to just use the different name here
find_source_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$target_word == x){
return(i)
}
}
}
## Extract recognition data
words <- unique(data$word)
for (i in 1:length(words)){
index <- find_recog_index(words[i],this.user.data$confidence_trials)
data$recog_rating[i] <- this.user.data$confidence_trials[[index]]$response
data$recog_RT[i] <- this.user.data$confidence_trials[[index]]$rt
}
## Extract source recall data
for (i in 1:length(words)){
index <- find_source_index(words[i],this.user.data$recall_trials)
data$target_angle[i] <- this.user.data$recall_trials[[index]]$target_angle
data$response_angle[i] <- this.user.data$recall_trials[[index]]$hitting_angle
data$response_error[i] <- this.user.data$recall_trials[[index]]$angular_error
data$source_RT[i] <- this.user.data$recall_trials[[index]]$response_time
data$valid_RT [i] <- (this.user.data$recall_trials[[index]]$num_fast_attempts == 0 &&
this.user.data$recall_trials[[index]]$num_slow_attempts == 0)
}
## Aggregate performance as reciprocal of the SD of angular error.
prec <- 1/sd(data$response_error)
## Plot histograms of response error and response times for this participant
library(ggplot2)
error <- ggplot(data = data, aes(x = response_error)) +
geom_histogram(bins = 30) +
labs(title ="All Recognition Ratings", x = "Response Error (radians)", y = "Frequency") +
theme_classic()
rt <- ggplot(data = data, aes(x = source_RT)) +
geom_histogram(bins = 30) +
labs(title ="All Recognition Ratings", x = "Response Time (ms)", y = "Frequency") +
theme_classic()
error
View(data)
0.425 - 3.88
(0.425 - 3.88) + pi
(0.425 - 3.88) + 2*pi
(0.425 - 3.88) - 2*pi
0.425 - 3.8
0.425 - 3.88
0.42525681 - 3.88379862
pi
0.42525681 - 3.88379862
(0.42525681 - 3.88379862) > 0
-pi
data <- data.frame(matrix(ncol=9,nrow=length(this.user.data$present_trials), dimnames=list(NULL, c("word", "is_sequential",
"recog_rating","recog_RT","target_angle",
"response_angle","response_error","source_RT", "valid_RT"))))
## Extract presentation data
for(i in 1:length(this.user.data$present_trials)){
data$word[i] <- this.user.data$present_trials[[i]]$target_word
data$is_sequential[i] <- this.user.data$present_trials[[i]]$presentation_sequential
}
## Function to sort through the scrambled blocks and find the index needed for extraction
find_recog_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$stimulus == x){
return(i)
}
}
}
## The stimulus word is called "target_angle" for the recall trials. Could change how it is named in the database,
## but easier for now to just use the different name here
find_source_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$target_word == x){
return(i)
}
}
}
## Extract recognition data
words <- unique(data$word)
for (i in 1:length(words)){
index <- find_recog_index(words[i],this.user.data$confidence_trials)
data$recog_rating[i] <- this.user.data$confidence_trials[[index]]$response
data$recog_RT[i] <- this.user.data$confidence_trials[[index]]$rt
}
## Extract source recall data
for (i in 1:length(words)){
index <- find_source_index(words[i],this.user.data$recall_trials)
data$target_angle[i] <- this.user.data$recall_trials[[index]]$target_angle
data$response_angle[i] <- this.user.data$recall_trials[[index]]$hitting_angle
data$response_error[i] <- this.user.data$recall_trials[[index]]$angular_error
## Correcting for an error in the old javascript calculation of angular error
if(data$response_error[i] < -pi){
data$response_error[i] <- data$response_error[i] + 4*pi
}
data$source_RT[i] <- this.user.data$recall_trials[[index]]$response_time
data$valid_RT [i] <- (this.user.data$recall_trials[[index]]$num_fast_attempts == 0 &&
this.user.data$recall_trials[[index]]$num_slow_attempts == 0)
}
## Aggregate performance as reciprocal of the SD of angular error.
prec <- 1/sd(data$response_error)
## Plot histograms of response error and response times for this participant
library(ggplot2)
error <- ggplot(data = data, aes(x = response_error)) +
geom_histogram(bins = 30) +
labs(title ="All Recognition Ratings", x = "Response Error (radians)", y = "Frequency") +
theme_classic()
rt <- ggplot(data = data, aes(x = source_RT)) +
geom_histogram(bins = 30) +
labs(title ="All Recognition Ratings", x = "Response Time (ms)", y = "Frequency") +
theme_classic()
## Save all users data
# for(i in 1:length(completed.users)){
#   this.user.data <- get.last.experiment.data.by.user.id(SERVER.BASE.URL, completed.users[[i]],
#                                                         SERVER.PORT, SERVER.MASTER.API.KEY)
#   filename = sprintf('Subject%s.RData', i)
#   save(this.user.data, file = filename)
# }
error
rt
setwd('C:/Users/jason/Documents/GitHub/sourcemem_online/experiment/stimuli')
all_words <- read.csv("subtlexLength.csv")
words_length <- all_words[all_words$length == 4,]
words_length_freq <- words_length[(words_length$SUBTLWF<7.5),]
words_length_freq <- words_length_freq[(words_length_freq$SUBTLWF>0.75),]
write.csv(words_length_freq, file = "wordlist_WF7_5.csv")
setwd('C:/Users/jason/Documents/GitHub/sourcemem_online/experiment/stimuli')
all_words <- read.csv("subtlexLength.csv")
words_length <- all_words[all_words$length == 4,]
words_length_freq <- words_length[(words_length$SUBTLWF<8),]
words_length_freq <- words_length_freq[(words_length_freq$SUBTLWF>0.75),]
write.csv(words_length_freq, file = "wordlist_WF8.csv")
source('~/GitHub/sourcemem_online/experiment/stimuli/csv_to_json.R', echo=TRUE)
source('~/GitHub/sourcemem_online/experiment/stimuli/csv_to_json.R', echo=TRUE)
library(jsonlite)
setwd("~/GitHub/sourcemem_online/experiment/stimuli")
json_s1 <- toJSON(sessions[1], pretty = TRUE)
json_s2 <- toJSON(sessions[2], pretty = TRUE)
json_s3 <- toJSON(sessions[3], pretty = TRUE)
json_s1 <- toJSON(sessions[1])
json_s2 <- toJSON(sessions[2])
json_s3 <- toJSON(sessions[3])
json_s1
jsonwords <- toJSON(words, pretty = TRUE)
toJSON
source('~/GitHub/sourcemem_online/experiment/stimuli/csv_to_json.R', echo=TRUE)
json_s1
View(sessions)
json_s2
json_s3
knitr::opts_chunk$set(echo = TRUE)
setwd('C:/Users/jason/Documents/GitHub/sourcemem_online/experiment/stimuli')
all_words <- read.csv("subtlexLength.csv")
words_length <- all_words[all_words$length == 4,]
words_length_freq <- words_length[(words_length$SUBTLWF<7.5),]
words_length_freq <- words_length_freq[(words_length_freq$SUBTLWF>0.75),]
write.csv(words_length_freq, file = "additional_words.csv")
setwd('C:/Users/jason/Documents/GitHub/sourcemem_online/experiment/stimuli')
all_words <- read.csv("subtlexLength.csv")
words_length <- all_words[all_words$length == 4,]
words_length_freq <- words_length[(words_length$SUBTLWF<7.5),]
words_length_freq <- words_length_freq[(words_length_freq$SUBTLWF>7),]
write.csv(words_length_freq, file = "additional_words.csv")
setwd('C:/Users/jason/Documents/GitHub/sourcemem_online/experiment/stimuli')
all_words <- read.csv("subtlexLength.csv")
words_length <- all_words[all_words$length == 4,]
words_length_freq <- words_length[(words_length$SUBTLWF<8),]
words_length_freq <- words_length_freq[(words_length_freq$SUBTLWF>7.5),]
write.csv(words_length_freq, file = "additional_words.csv")
source('~/GitHub/sourcemem_online/experiment/stimuli/csv_to_json.R', echo=TRUE)
json_s1
View(sessions)
View(sessions)
745/3
754/3
jsonwords <- toJSON(words, pretty = TRUE)
source('~/GitHub/sourcemem_online/experiment/stimuli/csv_to_json.R', echo=TRUE)
View(sessions)
json_s1
View(sessions)
245*3
