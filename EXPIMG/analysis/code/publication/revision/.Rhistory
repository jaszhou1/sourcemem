#dataset <- dataset[!(dataset$participant== 1),]
#dataset <- dataset[!(dataset$participant== 13),]
# Get a list of subjects
data.subjList <- unique(dataset$participant)
#data.subjList <- c(1,2,3,4)
# Custom function to create new variable labels
create.subj.string <- function(subjNo, dataset){
dataset[dataset$participant==subjNo, 'subjString'] <- sprintf('Subject %d', subjNo)
return(dataset)
}
# Run through loop - don't use lapply or map because subject numbers not in order
for (sub in 1:length(data.subjList)){
# Get the subject number
subjNo <- data.subjList[sub]
# Run function, return data frame (dataset)
dataset <- create.subj.string(subjNo, dataset)
}
# Create as factor for plotting and also include levels so the order is correct
dataset$subjString <- factor(dataset$subjString,
levels = unique(dataset$subjString))
dataset$participant <- factor(dataset$participant, levels = unique(dataset$participant))
recogdata <- dataset[dataset$recog_rating>3,]
lowdata <- recogdata[recogdata$condition==1,]
highdata <- recogdata[recogdata$condition==2,]
View(highdata)
View(lowdata)
rm(list = ls())
# knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(plyr)
library(tidyverse)
library(readr)
library(abind)
knitr::opts_knit$set(root.dir = "~/GitHub/sourcemem/models/figures/cDiffusionFits")
dataset <- read.csv("2020-01-02_NoCritQQ_Hybrid.csv")
dataset$quantile_idx <- as.factor(dataset$quantile_idx)
# Create a new variable to label the subject numbers as strings
dataset$subjString <- NA
# Get a list of subjects
data.subjList <- unique(dataset$participant)
# Custom function to create new variable labels
create.subj.string <- function(n, dataset){
dataset[dataset$participant==n, 'subjString'] <- sprintf("Subject %d", n)
return(dataset)
}
# Run through loop - don't use lapply or map because subject numbers not in order
for (sub in 1:length(data.subjList)){
# Get the subject number
subjNo <- data.subjList[sub]
# Run function, return data frame (dataset)
dataset <- create.subj.string(subjNo, dataset)
}
# Create as factor for plotting and also include levels so the order is correct
dataset$subjString <- factor(dataset$subjString,
levels = unique(dataset$subjString))
# Get a list of the subject strings you created just to double check
data.subjString <- unique(dataset$subjString)
#Custom function to subset model predictions within the minimum and maximum bin of response
truncate.model <-function(dataset){
res <- data.frame()
participants <- unique(dataset$participant)
for(p in participants) {
min.error <- min(dataset[(dataset$participant == p) &
(dataset$is_model == " false"), 'theta'])
max.error <- max(dataset[(dataset$participant == p) &
(dataset$is_model == " false"), 'theta'])
res <- rbind(res,
dataset[(dataset$participant == p) &
(dataset$is_model == " false"), ])
res <- rbind(res,
dataset[(dataset$participant == p) &
(dataset$is_model == " true") &
(dataset$theta < max.error) &
(dataset$theta > min.error), ])
}
res
}
dataset_b <- truncate.model(dataset)
data_low <- dataset_b[(dataset_b$is_model==' false') & (dataset_b$is_high==' false'),]
model_low <- dataset_b[(dataset_b$is_model==' true') & (dataset_b$is_high==' false'),]
data_high <- dataset_b[(dataset_b$is_model==' false') & (dataset_b$is_high==' true'),]
model_high <- dataset_b[(dataset_b$is_model==' true') & (dataset_b$is_high==' true'),]
#Find means across high and low imageability conditions
data <- setNames(data.frame(matrix(ncol = 6, nrow = nrow(data_low))),
c("subject", "theta_high","theta_low",
"rt_high","rt_low","quantile_idx"))
#Data
data$subject <- data_high$subjString
data$theta_high <- data_high$theta
data$theta_low <- data_low$theta
data$rt_high <- data_high$rt
data$rt_low <- data_low$rt
data$quantile_idx <- data_high$quantile_idx
data$theta_mean <- rowMeans(data[c('theta_high', 'theta_low')], na.rm=TRUE)
data$rt_mean <- rowMeans(data[c('rt_high', 'rt_low')], na.rm=TRUE)
#Convert to Absolute
#Split dataframe by subject
splitData<- split(data, data$subject)
# Custom function to convert QxQ data into absolute (average absolute theta, average rt)
#to.absolute <- function(n, dataset){
#}
#lapply(splitData, to.absolute)
#Hybrid Model
#model <- model_high
# The palette with grey:
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# The palette with black:
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# Setup equally spaced colours around wheel
gg_color_hue <- function(n) {
hues = seq(15, 375, length = n + 1)
hcl(h = hues, l = 65, c = 100)[1:n]
}
n = 3
cols = gg_color_hue(n)
# ------------ Plot Data ---------------------------------
QxQ <- ggplot() +
# Plot data as POINTS ONLY
geom_point(data = data,
aes(x = data$theta_mean,
y = data$rt_mean,
group = data$quantile_idx,
colour = quantile_idx)) +
# ---------- Plot Model Predictions ----------------------
# Plot the model predictions as LINES
# Continuous
# Threshold
# Hybrid
# Theme
# ------------ Group plot by participant -----------------
facet_wrap(~subject, labeller = label_wrap_gen(width = 30), ncol = 4, scale = "free") +
# ------------ Change some axes settings  ----------------
#scale_y_continuous(limits=c(0, 3)) +
scale_x_continuous(name ="Response Error (degrees)", # also x axis name
breaks = c(-2, 0, 2),
labels = c(expression(-pi), "0", expression(pi))) +
xlab("Response Error (degrees)") + # just in case remove scale x continuous
ylab("Response Time (s)") +
scale_color_manual(name = "Predicted \nQuantiles",
values = cols,  # cbPalette[c(1,2,3)],
labels = c("0.1", "0.5", "0.9")) +
# ------------ Change Theme Settings  ----------------
ggtitle("Response Time Quantiles by Error \n High Imageability Condition") +
theme(
# Legend settings
#legend.justification = c(1, 1), legend.position = c(0.90, 1.09),
legend.background = element_blank(),
# Axis settingd
axis.text.x = element_text(size=7),  # size of text on the x axis
axis.text.y = element_text(size=7),  # size of text on the y axis
# Plot title settings
plot.title = element_text(hjust = 0.5, size = 13),  # title settings (note, centering requires h = 0.5)
plot.subtitle = element_text(hjust = 0.5), # subtitle settiings (note, centering requires h = 0.5)
plot.caption = element_text(hjust = 0, face = "italic"), # caption settings
# Get rid of background panel grid
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black"))
QxQ
started.users <- get.started.users(SERVER.BASE.URL, SERVER.PORT,
SERVER.MASTER.API.KEY)
SERVER.BASE.URL <- "https://jzhou-sourcemem-online.appspot.com"
SERVER.PORT <- NULL
SERVER.MASTER.API.KEY <- "zjFdXfQ64sgAVwQMx84IhzqzUPygpSguUkeLKLqQBIyxo8kP3yphBqF9ysd4IQsA" # <-- This needs to be in agreement with
# whatever is on the server.
#####
setwd("~/GitHub/sourcemem_online/analysis")
source("access-data.R")
sessions <- c(1,2,3)
## Get the started users
started.users <- get.started.users(SERVER.BASE.URL, SERVER.PORT,
SERVER.MASTER.API.KEY)
started.users
for(j in 1:length(sessions)){
this.session.data <- get.session.data.by.user.id(SERVER.BASE.URL, started.users[[2]], j,
SERVER.PORT, SERVER.MASTER.API.KEY)
## Extract the required information for each stimuli across the trial types.
data <- data.frame(matrix(ncol=9,nrow=length(this.session.data$present_trials), dimnames=list(NULL, c("word", "is_sequential",
"recog_rating","recog_RT","target_angle",
"response_angle","response_error","source_RT", "valid_RT"))))
## Extract presentation data
for(i in 1:length(this.session.data$present_trials)){
data$word[i] <- this.session.data$present_trials[[i]]$target_word
data$is_sequential[i] <- this.session.data$present_trials[[i]]$presentation_sequential
}
## Function to sort through the scrambled blocks and find the index needed for extraction
find_recog_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$stimulus == x){
return(i)
}
}
}
## The stimulus word is called "target_angle" for the recall trials. Could change how it is named in the database,
## but easier for now to just use the different name here
find_source_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$target_word == x){
return(i)
}
}
}
## Extract recognition data
words <- unique(data$word)
for (i in 1:length(words)){
index <- find_recog_index(words[i],this.session.data$confidence_trials)
data$recog_rating[i] <- this.session.data$confidence_trials[[index]]$response
data$recog_RT[i] <- this.session.data$confidence_trials[[index]]$rt
}
## Extract source recall data
for (i in 1:length(words)){
index <- find_source_index(words[i],this.session.data$recall_trials)
data$target_angle[i] <- this.session.data$recall_trials[[index]]$target_angle
data$response_angle[i] <- this.session.data$recall_trials[[index]]$hitting_angle
data$response_error[i] <- this.session.data$recall_trials[[index]]$angular_error
## Correcting for an error in the old javascript calculation of angular error
if(data$response_error[i] < -pi){
data$response_error[i] <- data$response_error[i] + 4*pi
}
data$source_RT[i] <- this.session.data$recall_trials[[index]]$response_time
data$valid_RT [i] <- (this.session.data$recall_trials[[index]]$num_fast_attempts == 0 &&
this.session.data$recall_trials[[index]]$num_slow_attempts == 0)
}
# Bind sessions together
this.user.data <- rbind(this.user.data,data)
# Filter out invalid RTs
this.user.data <- this.user.data[this.user.data$valid_RT == TRUE,]
}
## Aggregate performance as reciprocal of the SD of angular error.
prec <- 1/sd(data$response_error)
## Plot histograms of response error and response times for this participant
library(ggplot2)
error <- ggplot(data = this.user.data, aes(x = response_error)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Error (radians)", y = "Frequency") +
theme_classic()
rt <- ggplot(data = this.user.data, aes(x = source_RT)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Time (ms)", y = "Frequency") +
theme_classic()
## Save all users data
# for(i in 1:length(completed.users)){
#   this.user.data <- get.last.experiment.data.by.user.id(SERVER.BASE.URL, completed.users[[i]],
#                                                         SERVER.PORT, SERVER.MASTER.API.KEY)
#   filename = sprintf('Subject%s.RData', i)
#   save(this.user.data, file = filename)
# }
error
error
for(j in 1:length(sessions)){
this.session.data <- get.session.data.by.user.id(SERVER.BASE.URL, started.users[[2]], j,
SERVER.PORT, SERVER.MASTER.API.KEY)
## Extract the required information for each stimuli across the trial types.
data <- data.frame(matrix(ncol=9,nrow=length(this.session.data$present_trials), dimnames=list(NULL, c("word", "is_sequential",
"recog_rating","recog_RT","target_angle",
"response_angle","response_error","source_RT", "valid_RT"))))
## Extract presentation data
for(i in 1:length(this.session.data$present_trials)){
data$word[i] <- this.session.data$present_trials[[i]]$target_word
data$is_sequential[i] <- this.session.data$present_trials[[i]]$presentation_sequential
}
## Function to sort through the scrambled blocks and find the index needed for extraction
find_recog_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$stimulus == x){
return(i)
}
}
}
## The stimulus word is called "target_angle" for the recall trials. Could change how it is named in the database,
## but easier for now to just use the different name here
find_source_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$target_word == x){
return(i)
}
}
}
## Extract recognition data
words <- unique(data$word)
for (i in 1:length(words)){
index <- find_recog_index(words[i],this.session.data$confidence_trials)
data$recog_rating[i] <- this.session.data$confidence_trials[[index]]$response
data$recog_RT[i] <- this.session.data$confidence_trials[[index]]$rt
}
## Extract source recall data
for (i in 1:length(words)){
index <- find_source_index(words[i],this.session.data$recall_trials)
data$target_angle[i] <- this.session.data$recall_trials[[index]]$target_angle
data$response_angle[i] <- this.session.data$recall_trials[[index]]$hitting_angle
data$response_error[i] <- this.session.data$recall_trials[[index]]$angular_error
## Correcting for an error in the old javascript calculation of angular error
if(data$response_error[i] < -pi){
data$response_error[i] <- data$response_error[i] + 4*pi
}
data$source_RT[i] <- this.session.data$recall_trials[[index]]$response_time
data$valid_RT [i] <- (this.session.data$recall_trials[[index]]$num_fast_attempts == 0 &&
this.session.data$recall_trials[[index]]$num_slow_attempts == 0)
}
# Bind sessions together
this.user.data <- rbind(this.user.data,data)
# Filter out invalid RTs
this.user.data <- this.user.data[this.user.data$valid_RT == TRUE,]
}
## Aggregate performance as reciprocal of the SD of angular error.
prec <- 1/sd(data$response_error)
## Plot histograms of response error and response times for this participant
library(ggplot2)
error <- ggplot(data = this.user.data, aes(x = response_error)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Error (radians)", y = "Frequency") +
theme_classic()
rt <- ggplot(data = this.user.data, aes(x = source_RT)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Time (ms)", y = "Frequency") +
theme_classic()
## Save all users data
# for(i in 1:length(completed.users)){
#   this.user.data <- get.last.experiment.data.by.user.id(SERVER.BASE.URL, completed.users[[i]],
#                                                         SERVER.PORT, SERVER.MASTER.API.KEY)
#   filename = sprintf('Subject%s.RData', i)
#   save(this.user.data, file = filename)
# }
this.user.data = data.frame()
for(j in 1:length(sessions)){
this.session.data <- get.session.data.by.user.id(SERVER.BASE.URL, started.users[[2]], j,
SERVER.PORT, SERVER.MASTER.API.KEY)
## Extract the required information for each stimuli across the trial types.
data <- data.frame(matrix(ncol=9,nrow=length(this.session.data$present_trials), dimnames=list(NULL, c("word", "is_sequential",
"recog_rating","recog_RT","target_angle",
"response_angle","response_error","source_RT", "valid_RT"))))
## Extract presentation data
for(i in 1:length(this.session.data$present_trials)){
data$word[i] <- this.session.data$present_trials[[i]]$target_word
data$is_sequential[i] <- this.session.data$present_trials[[i]]$presentation_sequential
}
## Function to sort through the scrambled blocks and find the index needed for extraction
find_recog_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$stimulus == x){
return(i)
}
}
}
## The stimulus word is called "target_angle" for the recall trials. Could change how it is named in the database,
## but easier for now to just use the different name here
find_source_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$target_word == x){
return(i)
}
}
}
## Extract recognition data
words <- unique(data$word)
for (i in 1:length(words)){
index <- find_recog_index(words[i],this.session.data$confidence_trials)
data$recog_rating[i] <- this.session.data$confidence_trials[[index]]$response
data$recog_RT[i] <- this.session.data$confidence_trials[[index]]$rt
}
## Extract source recall data
for (i in 1:length(words)){
index <- find_source_index(words[i],this.session.data$recall_trials)
data$target_angle[i] <- this.session.data$recall_trials[[index]]$target_angle
data$response_angle[i] <- this.session.data$recall_trials[[index]]$hitting_angle
data$response_error[i] <- this.session.data$recall_trials[[index]]$angular_error
## Correcting for an error in the old javascript calculation of angular error
if(data$response_error[i] < -pi){
data$response_error[i] <- data$response_error[i] + 4*pi
}
data$source_RT[i] <- this.session.data$recall_trials[[index]]$response_time
data$valid_RT [i] <- (this.session.data$recall_trials[[index]]$num_fast_attempts == 0 &&
this.session.data$recall_trials[[index]]$num_slow_attempts == 0)
}
# Bind sessions together
this.user.data <- rbind(this.user.data,data)
# Filter out invalid RTs
this.user.data <- this.user.data[this.user.data$valid_RT == TRUE,]
}
## Aggregate performance as reciprocal of the SD of angular error.
prec <- 1/sd(data$response_error)
## Plot histograms of response error and response times for this participant
library(ggplot2)
error <- ggplot(data = this.user.data, aes(x = response_error)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Error (radians)", y = "Frequency") +
theme_classic()
rt <- ggplot(data = this.user.data, aes(x = source_RT)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Time (ms)", y = "Frequency") +
theme_classic()
## Save all users data
# for(i in 1:length(completed.users)){
#   this.user.data <- get.last.experiment.data.by.user.id(SERVER.BASE.URL, completed.users[[i]],
#                                                         SERVER.PORT, SERVER.MASTER.API.KEY)
#   filename = sprintf('Subject%s.RData', i)
#   save(this.user.data, file = filename)
# }
error
rt
this.user.data = data.frame()
for(j in 1:length(sessions)){
this.session.data <- get.session.data.by.user.id(SERVER.BASE.URL, started.users[[3]], j,
SERVER.PORT, SERVER.MASTER.API.KEY)
## Extract the required information for each stimuli across the trial types.
data <- data.frame(matrix(ncol=9,nrow=length(this.session.data$present_trials), dimnames=list(NULL, c("word", "is_sequential",
"recog_rating","recog_RT","target_angle",
"response_angle","response_error","source_RT", "valid_RT"))))
## Extract presentation data
for(i in 1:length(this.session.data$present_trials)){
data$word[i] <- this.session.data$present_trials[[i]]$target_word
data$is_sequential[i] <- this.session.data$present_trials[[i]]$presentation_sequential
}
## Function to sort through the scrambled blocks and find the index needed for extraction
find_recog_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$stimulus == x){
return(i)
}
}
}
## The stimulus word is called "target_angle" for the recall trials. Could change how it is named in the database,
## but easier for now to just use the different name here
find_source_index <- function(x, list){
for (i in 1:length(list)){
if (list[[i]]$target_word == x){
return(i)
}
}
}
## Extract recognition data
words <- unique(data$word)
for (i in 1:length(words)){
index <- find_recog_index(words[i],this.session.data$confidence_trials)
data$recog_rating[i] <- this.session.data$confidence_trials[[index]]$response
data$recog_RT[i] <- this.session.data$confidence_trials[[index]]$rt
}
## Extract source recall data
for (i in 1:length(words)){
index <- find_source_index(words[i],this.session.data$recall_trials)
data$target_angle[i] <- this.session.data$recall_trials[[index]]$target_angle
data$response_angle[i] <- this.session.data$recall_trials[[index]]$hitting_angle
data$response_error[i] <- this.session.data$recall_trials[[index]]$angular_error
## Correcting for an error in the old javascript calculation of angular error
if(data$response_error[i] < -pi){
data$response_error[i] <- data$response_error[i] + 4*pi
}
data$source_RT[i] <- this.session.data$recall_trials[[index]]$response_time
data$valid_RT [i] <- (this.session.data$recall_trials[[index]]$num_fast_attempts == 0 &&
this.session.data$recall_trials[[index]]$num_slow_attempts == 0)
}
# Bind sessions together
this.user.data <- rbind(this.user.data,data)
# Filter out invalid RTs
this.user.data <- this.user.data[this.user.data$valid_RT == TRUE,]
}
## Aggregate performance as reciprocal of the SD of angular error.
prec <- 1/sd(data$response_error)
## Plot histograms of response error and response times for this participant
library(ggplot2)
error <- ggplot(data = this.user.data, aes(x = response_error)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Error (radians)", y = "Frequency") +
theme_classic()
rt <- ggplot(data = this.user.data, aes(x = source_RT)) +
geom_histogram(bins = 50) +
labs(title ="All Recognition Ratings", x = "Response Time (ms)", y = "Frequency") +
theme_classic()
## Save all users data
# for(i in 1:length(completed.users)){
#   this.user.data <- get.last.experiment.data.by.user.id(SERVER.BASE.URL, completed.users[[i]],
#                                                         SERVER.PORT, SERVER.MASTER.API.KEY)
#   filename = sprintf('Subject%s.RData', i)
#   save(this.user.data, file = filename)
# }
error
quantiles <- read.csv('2020-09-07-18-23_mix_high_conf_joint.csv')
setwd("~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision")
quantiles <- read.csv('2020-09-07-18-23_mix_high_conf_joint.csv')
models$is_model <- quantiles$is_model == ' true'
## Read in empirical data
dataset <- quantiles$is_model == ' false'
dataset$quantile_idx <- as.factor(dataset$quantile_idx)
models <- quantiles$is_model == ' true'
View(quantiles)
models <- quantiles[quantiles$is_model == ' true',]
dataset <- quantiles[quantiles$is_model == ' false',]
dataset$quantile_idx <- as.factor(dataset$quantile_idx)
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision/publicationfigure_qxq.R', echo=TRUE)
unique(as.character(models$model_name))
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision/publicationfigure_qxq.R', echo=TRUE)
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision/publicationfigure_qxq.R', echo=TRUE)
View(dataset)
unique(dataset$participant)
unique(models$participant)
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision/publicationfigure_qxq.R', echo=TRUE)
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision/publicationfigure_qxq.R', echo=TRUE)
setwd("~/GitHub/sourcemem/EXPIMG/models/code/simulation")
setwd("~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision")
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision/simulation_qxq.R', echo=TRUE)
unique(dataset$participant)
length(unique(dataset$participant))
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision/simulation_qxq.R', echo=TRUE)
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/publicationfigure_qxq.R', echo=TRUE)
setwd("~/GitHub/sourcemem/EXPIMG/analysis/code/publication")
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/publicationfigure_qxq.R', echo=TRUE)
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/publicationfigure_qxq.R', echo=TRUE)
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision/simulation_qxq.R', echo=TRUE)
setwd("~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision")
source('~/GitHub/sourcemem/EXPIMG/analysis/code/publication/revision/simulation_qxq.R', echo=TRUE)
View(models)
